
```` Key Concepts and Practices in Software Testing Life Cycle (STLC) ````

================================================================================
--- Core STLC Concepts ---

================================================================================
@Definition :
    Software Testing Life Cycle (STLC) is a sequence of phases followed to test software systematically and ensure its quality before release.

STLC Stages (Brief):
    Requirement Analysis: Understand and analyze testable requirements.    
    Test Planning: Prepare the test strategy, scope, and schedule.
    Test Case Design: Create test cases and scripts.
    Test Environment Setup: Configure the environment and tools for testing.
    Test Execution: Run tests and record results.
    Defect Reporting: Log and track bugs found.
    Test Closure: Review testing, report results, and document lessons learned.
    Retesting & Regression Testing: Verify fixes and check for new issues.
================================================================================

--- Testing Techniques & Strategies ---

================================================================================
Q. What is verification and validation in testing?  
A: Verification checks if the product is being built correctly by reviewing documents, designs, and processes.  
    Validation ensures the final product works as expected for the user by executing tests on the actual software.
================================================================================
Q. What is boundary value analysis (BVA)?  
A: BVA is a technique that tests at the edge of input ranges where errors are most likely.  
    It includes values just below, at, and just above the boundaries to ensure the system handles edge cases correctly.
================================================================================
Q. What is equivalence partitioning?  
A: It divides input data into valid and invalid partitions where each group is expected to behave the same.  
    Testing one value from each group is considered sufficient to represent that entire partition.
================================================================================
Q. What is exploratory testing?  
A: Exploratory testing combines learning, test design, and execution simultaneously.  
    It relies on the tester's experience and creativity to find unexpected issues.
================================================================================
Q. What is error guessing?  
A: Error guessing is a technique where testers anticipate potential defects based on past experience.  
    It involves creating test cases around common or historically problematic areas in the application.
================================================================================
Q. What is the difference between blackbox and whitebox testing?  
A: Blackbox testing checks application functionality without knowing its internal code.  
    Whitebox testing is based on code structure and logic, ensuring internal components behave correctly.
================================================================================ 
Q. What is Branch Testing?
A: Branch Testing is a white-box testing technique where each possible branch or decision in the code is tested at least once. 
    It ensures that both true and false outcomes of conditions (like if-else) are covered, helping to find logical errors in decision-making.
================================================================================
Q: What is Boundary Testing?
A: Boundary Testing is a black-box testing technique that focuses on testing the input values at the edges or boundaries of valid input ranges. 
    It checks values like minimum, maximum, just below minimum, and just above maximum to detect errors at the limits.
================================================================================

--- Test Management & Planning ---

================================================================================
Q. What is a test plan?  
A: A Test Plan is a formal document that outlines the scope, objectives, resources, schedule, and approach for testing a project.
    It serves as a roadmap to guide the testing team and ensure testing is aligned with business goals and carried out systematically.
   
It typically includes:
    Test objectives: What needs to be tested and goals.
    Scope: Features to be tested and out of scope.
    Test approach: Testing types and methods used.
    Test environment: Hardware, software, and tools required.
    Test schedule: Timeline and milestones.
    Resource allocation: Team roles and responsibilities.
    Entry and exit criteria: Conditions to start and stop testing.
    Risks and contingencies: Potential issues and mitigation plans.
    Deliverables: Test cases, reports, logs, etc.
================================================================================
Q. What is RTM (Requirement Traceability Matrix)?  
A: RTM maps requirements to corresponding test cases to ensure complete test coverage.  
    It helps track changes and ensures that no requirement is left untested.
================================================================================
Q. What is a test closure report?  
A: It summarizes all testing activities, results, defects, and quality metrics at the end of the testing cycle.  
    The report provides insights, lessons learned, and recommendations for future projects.
================================================================================
Q. What reports are used in testing?  
A: Common reports include Test Summary, Bug Reports, Execution Reports, Coverage Reports, and RTM.  
    These documents help track testing progress, defect status, and overall product quality.
================================================================================

--- Defects & Prioritization ---

================================================================================
Q. How do you prioritize test cases?  
A: Test cases are prioritized based on risk, requirement criticality, severity, and business needs.  
    Higher priority is given to test cases affecting critical features or areas prone to failure.
================================================================================
Q. Define severity and priority.  
A: Severity reflects the impact of a defect on the application’s functionality.  
    Priority indicates how soon the defect should be fixed from a business perspective.
================================================================================
Q. What is a showstopper defect?  
A: A showstopper defect is a critical issue that blocks further testing or usage of the application.  
    Testing is suspended until the defect is resolved, as it hinders core functionality.
================================================================================

--- Types of Testing ---

================================================================================
Q. What is smoke vs sanity testing?  
A: Smoke testing verifies major functionalities to confirm a build’s stability for further testing.  
    Sanity testing focuses on verifying specific functionalities or bug fixes after minor changes.
================================================================================
Q. What is regression testing?  
A: It ensures that recent code changes haven’t negatively impacted existing features.  
    Regression tests are repeated for every build to maintain application stability.
================================================================================
Q. What is retesting?  
A: Retesting involves executing failed test cases after defects are fixed to confirm they are resolved.  
    It is done on the same environment using the same inputs to ensure accuracy.
================================================================================
Q. What is integration testing?  
A: Integration testing validates the interaction between integrated modules.  
    It checks for interface issues and data flow correctness between connected components.
================================================================================
Q. What is topdown vs bottomup testing?  

Top-Down Integration Testing:
    Testing starts from the top-level modules and progresses downwards to the lower-level modules.
    Higher-level modules are tested first, and lower modules are integrated step by step.
    If lower modules are not yet developed, stubs (dummy modules) are used to simulate their behavior.
    Advantage: Early validation of high-level design and major control flows.
    Disadvantage: Lower-level modules are tested late, and stubs can be complex to create.

Bottom-Up Integration Testing:
    Testing begins with the lower-level modules and moves upward to higher-level modules.
    Lower modules are tested first, then integrated into higher modules progressively.
    If higher modules are not yet developed, drivers (test harnesses) are used to simulate their calls.
    Advantage: Detailed testing of foundational modules early.
    Disadvantage: The overall system design is validated late.
================================================================================
Q. What is big bang testing?  
    In big bang testing, all components are integrated at once and tested collectively.  
    It can be risky as defects are harder to isolate and may impact multiple areas.
================================================================================

--- Special Testing Types ---

================================================================================
Q. What is A/B testing?  
A: A/B testing compares two versions of a product to evaluate which one performs better with users.  
    It helps optimize UI/UX or feature effectiveness based on realworld feedback.
================================================================================
Q. What is concurrency testing?  
A: Concurrency testing verifies the application can handle multiple operations simultaneously.  
    It checks for issues like deadlocks, race conditions, or performance degradation.
================================================================================
Q. What is interface testing?  
A: It tests the data flow and interaction between client, server, and database components.  
    The goal is to ensure correct communication and data handling across layers.
================================================================================
Q. What is monkey, gorilla, and adhoc testing?  
A:  Monkey Testing: Random testing without predefined inputs or logic.  
     Gorilla Testing: Repeatedly testing one functionality heavily to check its robustness.  
     Adhoc Testing: Unstructured testing to explore and find defects intuitively.
================================================================================

--- Advanced Concepts ---

================================================================================
Q. What is shiftleft testing?  
A: Shiftleft testing means involving testing activities earlier in the development process.  
    It leads to early bug detection, better collaboration, and reduced cost of fixes.
================================================================================
Q. What are challenges in STLC?  
A: Challenges include unclear requirements, communication gaps, resource constraints, and tool compatibility issues.  
    They can affect test coverage, execution speed, and overall product quality.
================================================================================
Q. How do you integrate automation in STLC?  
A:  Select repetitive and highrisk test cases, then automate them using suitable tools and frameworks.  
    Integrate tests into CI/CD for continuous execution and faster feedback.
================================================================================
Q. How do you handle flaky tests?  
A: Analyze flaky tests for timing, environment, or data issues and stabilize them using waits or test isolation.  
    Regular reviews and root cause analysis help maintain test reliability.
================================================================================
Q. What is error seeding?  
A: Error seeding involves deliberately inserting known defects into the system.  
    It helps measure the effectiveness of the testing process and testers’ ability to detect bugs.
================================================================================
Q. What is risk mitigation in testing?  
A: Risk mitigation identifies potential risks and applies controls to reduce their impact.  
    This ensures testing efforts are focused and resources are efficiently utilized.
================================================================================